{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a style='color:#094FA4; font-size:25px'><b>Python Modeling Part 1: Data Exploration with Pandas</b></a>\n",
    "\n",
    "This week's challenge is Part 1 in a 3 part series providing an introduction to modeling in python. The first part will focus on reading data into Pandas and doing some preliminary data exploration. Part 2 will cover correlations and simple linear regressions between 2 or 3 variables. Part 3 will cover decision trees. These sessions won't be all-inclusive, but will hopefully give you a good jumping off point.\n",
    "\n",
    "The structure of this week's challenge is a bit different. As the topics in Python get more complex, it has become more difficult to create \"puzzles\". This challenge will read more like a homework assignment. We've provided some starter code to import the libraries and read in the data, and we've asked some questions that will require learning the basics of Pandas to answer. This will be necessary as a precursor to Parts 2 and 3.\n",
    "\n",
    "You will need to download the following two CSV files. (Right click \"Raw\", Save Link As)\n",
    "https://github.com/Marek-Sedlacek/Python_Challenges/blob/master/Files/Python%20Challenge%20%2310%20-%20Earthquake.csv\n",
    "https://github.com/Marek-Sedlacek/Python_Challenges/blob/master/Files/Python%20Challenge%20%2310%20-%20Earthquake_Supplement.csv\n",
    "\n",
    "\n",
    "For those that prefer a traditional challenge, we have a bonus question at the end dealing with random sampling and the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a style='color:#6698FF; font-size:20px'><b> Starter Code </b> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>MAGNITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-2150</td>\n",
       "      <td>JORDAN</td>\n",
       "      <td>7.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-2000</td>\n",
       "      <td>SYRIA</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-2000</td>\n",
       "      <td>TURKMENISTAN</td>\n",
       "      <td>7.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5877</td>\n",
       "      <td>-1610</td>\n",
       "      <td>GREECE</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>-1566</td>\n",
       "      <td>ISRAEL</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  YEAR       COUNTRY  MAGNITUDE\n",
       "0     1 -2150        JORDAN      7.300\n",
       "1     2 -2000         SYRIA        nan\n",
       "2     3 -2000  TURKMENISTAN      7.100\n",
       "3  5877 -1610        GREECE        nan\n",
       "4     8 -1566        ISRAEL        nan"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Pandas formatting options (not necessary, but helpful)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "#Read in the Earthquake csv file\n",
    "eq = pd.read_csv('Python Challenge #10 - Earthquake.csv')\n",
    "\n",
    "#Display the first 5 rows\n",
    "eq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<a style='color:#6698FF; font-size:20px'><b> Questions </b> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) How many earthquakes are in the data?\n",
    "Return the number of rows in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) What time frame does this data cover?\n",
    "Return the Minimum and Maximum Year in the dataframe. \n",
    "\n",
    "Remember, to select a single column use the format: _dataframe[\"Field\"]_ or _dataframe.Field_ In SQL, this is equivalent to:\n",
    "\n",
    "    SELECT Field FROM dataframe;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a) How many Earthquakes are missing a Magnitude?\n",
    "Return the number of records with a null value for Magnitude\n",
    "\n",
    "The *is_null()* function can be used to determine if a field is NaN (Not a Number, Null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b) Create a new dataframe excluding all rows without a Magnitude.\n",
    "Subset the data to only choose rows where Magnitude is not null, and store in a new dataframe variable\n",
    "\n",
    "To subset the data based on a condition, use the _dataframe[conditional]_ method. For example, _data[data[\"Field\"] > 0]_ is the same as:\n",
    "    \n",
    "    SELECT * FROM data WHERE Field > 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Which country had the most number of earthquakes?\n",
    "Group the new dataframe by country, count the number of rows, and return the record with the highest number of earthquakes\n",
    "\n",
    "You can group a dataframe using the _data.groupby('Field')_ method. However, this will only return a DataFrameGroupBy object until you apply an operation to it, such as _data.groupby('Field').sum()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Join a secondary dataset to your Earthquakes dataframe\n",
    "At this point in the challenge you should have a dataframe of Earthquakes that were not missing a Magnitude value. Now we want to read in a second dataset and join a single field from that dataset to the Earthquakes dataframe.\n",
    "\n",
    "    First, read in the new data from the Earthquake Supplement csv. \n",
    "    Limit the new dataframe to only the columns 'ID' and 'DEATHS'\n",
    "    Left join the new dataframe to your Earthquakes dataframe using the merge() function on the 'ID' field\n",
    "    Finally, display the first 10 rows of your new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6a) When and where was the earthquake with the most number of deaths.\n",
    "Return the country and year of the earthquake with the highest number of deaths\n",
    "\n",
    "To sort the data based on a field, use the *data.sort_values(by = \"Field\")* method. The SQL equivalent is:\n",
    "    \n",
    "    SELECT * FROM data ORDER BY Field;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6b) When and where was the earthquake with the most number of deaths in the 20th century\n",
    "Filter the dataframe to years after 1899, and return the country and year of the earthquake with the highest number of deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Which 3 countries had the most earthquakes with over 100 deaths after the year 1000?\n",
    "    Filter the dataframe to records with more than 100 deaths and year greater than 1000\n",
    "    Group the filtered dataframe by country\n",
    "    Count the number of records\n",
    "    Return the top 3 countries sorted by count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<a style='color:#6698FF; font-size:20px'><b> Bonus </b> </a>\n",
    "### How many randomly sampled  points do you need to get a population average?\n",
    "\n",
    "The central limit theorem (CLT) is a statistical theory that states that given a sufficiently large sample size from a population with a finite level of variance, the mean of all samples from the same population will be approximately equal to the mean of the population. This is an important theorem in modeling, because we frequently build our models off a random subset of the total dataset. We need to be certain that the sample accurately represents the population, and the CLT provides some guarantees around this. While the cutoff point for a minimum sample size varies, it is generally much smaller than one would expect. \n",
    "\n",
    "For the Earthquakes dataset (excluding Nulls), find the average minimum sample size needed to obtain the population average for Magnitude (within 1% variance).\n",
    "\n",
    "_Note: There is not a definitive answer to this problem. Rather, a good solution should highlight a good process and have a result within a reasonable range of expectations. Double bonus points for any creative solutions!_\n",
    "\n",
    "<br>\n",
    "#### Spoilers/Hints:\n",
    "Below are some hints for how to solve the problem. If you want to solve on your own, skip over the following.\n",
    "\n",
    "<br>\n",
    "First calculate the mean Magnitude for the population. Then randomly sample a single Magnitude from the earthquakes data. Compare your sample mean to the population mean. If the sample mean is within 1% of the population mean, return the sample size (1). Else, randomly sample another another record and calculate the new sample mean. Repeat this process until you are within 1% of the pop mean and return the sample size. Set up a function to repeat this process multiple times and take the average sample size of all the runs. \n",
    "\n",
    "The more iterations you run, the more reliable your avearge sample size will be but the longer your simulation will take. We highly suggest setting a timer on your loops before leaping to a 1,000,000 set simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
